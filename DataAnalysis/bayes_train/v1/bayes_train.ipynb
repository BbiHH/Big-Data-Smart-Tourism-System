{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import re, jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def processing(text):\n",
    "    \"\"\"\n",
    "    数据预处理, 可以根据自己的需求进行重载\n",
    "    \"\"\"\n",
    "    # 数据清洗部分\n",
    "    text = re.sub(\"\\{%.+?%\\}\", \" \", text)  # 去除 {%xxx%} (地理定位, 微博话题等)\n",
    "    text = re.sub(\"@.+?( |$)\", \" \", text)  # 去除 @xxx (用户名)\n",
    "    text = re.sub(\"【.+?】\", \" \", text)  # 去除 【xx】 (里面的内容通常都不是用户自己写的)\n",
    "    text = re.sub(\"\\u200b\", \" \", text)  # '\\u200b'是这个数据集中的一个bad case, 不用特别在意\n",
    "    # 分词\n",
    "    words = [w for w in jieba.lcut(text) if w.isalpha()]\n",
    "    # 对否定词`不`做特殊处理: 与其后面的词进行拼接\n",
    "    while \"不\" in words:\n",
    "        index = words.index(\"不\")\n",
    "        if index == len(words) - 1:\n",
    "            break\n",
    "        words[index: index + 2] = [\"\".join(words[index: index + 2])]  # 列表切片赋值的酷炫写法\n",
    "    # 用空格拼接成字符串\n",
    "    result = \" \".join(words)\n",
    "    return result\n",
    "\n",
    "\n",
    "def load_corpus(aaa):\n",
    "    \"\"\"\n",
    "    加载语料库\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for line in aaa:\n",
    "        content = processing(line)\n",
    "        data.append(content)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             content  score\n0  海南保亭的黎苗族风情景区，可以看到他们的艺术，居住环境，房屋，传统表演！大型艺术表演很有韵味...      0\n1  槟榔谷，大家都知道槟榔，也知道海南人有吃槟榔的习惯，初到三亚，就听说出租车司机朝窗外吐槟榔，...      0\n2  黎苗族文化主题公园，展示黎族、苗族服饰手工文化，传统民居，狩猎技能，传统舞蹈，民族美食，环境...      0\n3  去的那天太阳很大，带着儿子一起去的，里面主要是少数民族的传统习俗文化遗产等，导游讲解一下会更...      0\n4  该景点是海南游中比较值得去的地方，还有民族歌舞表演也值得看，这次和几家朋友自驾游，本来是想图...      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>海南保亭的黎苗族风情景区，可以看到他们的艺术，居住环境，房屋，传统表演！大型艺术表演很有韵味...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>槟榔谷，大家都知道槟榔，也知道海南人有吃槟榔的习惯，初到三亚，就听说出租车司机朝窗外吐槟榔，...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>黎苗族文化主题公园，展示黎族、苗族服饰手工文化，传统民居，狩猎技能，传统舞蹈，民族美食，环境...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>去的那天太阳很大，带着儿子一起去的，里面主要是少数民族的传统习俗文化遗产等，导游讲解一下会更...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>该景点是海南游中比较值得去的地方，还有民族歌舞表演也值得看，这次和几家朋友自驾游，本来是想图...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../csv/moredata_label.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "df['content'] = load_corpus(df['content'])  # 进行数据清洗"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 划分测试集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                content  score\n",
      "3684                                     主要 就是 参观 参观 而已      0\n",
      "5453                          免费 的 海滩 环境 一般般 去 看看 椰林 也好      0\n",
      "3140  三江 入海 的 玉带 滩 一边 的 江 平静 如 女孩 般 静谧 一边 的 大海 气势磅礴 ...      0\n",
      "144   去过 呀 诺达 再 来 槟榔 谷 真的 觉得 此处 更 像是 大型 旅游 商店 游览车 每到...      0\n",
      "2201                     不错 就是 交通 不太 方便 要是 有 专车 到 就 好 了      0\n",
      "...                                                 ...    ...\n",
      "6038                   假期 海滩 的 景色 不错 周末 的 时候 可以 来 这里 闲逛      0\n",
      "5067  这里 应该 可以 算是 海口市 一处 较 安全 干净 的 海滩 里面 的 烤炉 较 多 是 ...      0\n",
      "5586                             真的 不错 休闲 娱乐 为 一体 适合 游玩      0\n",
      "6224                         海没 三亚 那么 蓝 毕竟 是 内海 不过 别有风味      0\n",
      "5449                这里 推荐 过来 沙滩椅 元 三个 小时 有点像 阳光 一样 的 热情      1\n",
      "\n",
      "[4995 rows x 2 columns]                                                 content  score\n",
      "0     海南 保亭 的 黎 苗族 风情 景区 可以 看到 他们 的 艺术 居住 环境 房屋 传统 表...      0\n",
      "7     槟榔 谷 顾名思义 这是 一个 以 槟榔 树为 主题 且 以 观赏 休闲 为 目的 的 一个...      0\n",
      "21    这里 值得 一游 景色 很 美 节目 表演 完整 讲述 黎族 人 生活习惯 和 服饰 景区 ...      0\n",
      "24    黎族 非 遗产 物质 文化 国家 景区 挺 有 特色 的 就是 去 参观 黎族 和 苗族 的...      0\n",
      "25    去 的 时候 看 了 评价 不咋 的 有点 后悔 有点 被 骗 的 感觉 真的 去 了 感觉...      0\n",
      "...                                                 ...    ...\n",
      "6223                     去 了 很 多次 很 不错 图 推荐 突突突 突 看看 具体      0\n",
      "6226                         冬天 洗衣服 三天 不干 非常 潮 北方 人 受不了      1\n",
      "6227                        景点 一般 就是 一个 海边 沙滩 去 去 无妨 呵呵      0\n",
      "6232                            夏天 去 可能 会 更好 沙滩 漫长 还 不错      0\n",
      "6241                                很 适合 游泳 的 地方 大海 很 美      0\n",
      "\n",
      "[1249 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train = df.sample(frac=0.8, replace=False, random_state=0, axis=0)\n",
    "df_test = df[~df.index.isin(df_train.index)]\n",
    "print(df_train, df_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aris\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['a', 'ain', 'aren', 'c', 'couldn', 'd', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'i', 'isn', 'lex', 'll', 'm', 'mon', 's', 'shouldn', 't', 've', 'wasn', 'weren', 'won', 'wouldn', 'β', 'δ', 'λ', 'ξ', 'ψ', 'в', 'ⅲ', '①①', '①②', '①③', '①④', '①⑤', '①⑥', '①⑦', '①⑧', '①⑨', '①ａ', '①ｂ', '①ｃ', '①ｄ', '①ｅ', '①ｆ', '①ｇ', '①ｈ', '①ｉ', '①ｏ', '②①', '②②', '②③', '②④', '②⑤', '②⑥', '②⑦', '②⑧', '②⑩', '②ａ', '②ｂ', '②ｄ', '②ｅ', '②ｆ', '②ｇ', '②ｈ', '②ｉ', '②ｊ', '③①', '③⑩', '③ａ', '③ｂ', '③ｃ', '③ｄ', '③ｅ', '③ｆ', '③ｇ', '③ｈ', '④ａ', '④ｂ', '④ｃ', '④ｄ', '④ｅ', '⑤ａ', '⑤ｂ', '⑤ｄ', '⑤ｅ', '⑤ｆ', '元', '吨', '数', '日', '末', '０', '１', '１２', '２', '３', '５', 'ａ', 'ｂ', 'ｃ', 'ｅ', 'ｆ', 'ｌ', 'ｌｉ', 'ｒ', 'ｚｘｆｉｔｌ'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "stopwords = []\n",
    "with open(\"../stop.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    for w in f:\n",
    "        stopwords.append(w.strip())\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern='\\[?\\w+\\]?', stop_words=stopwords)\n",
    "#vectorizer = CountVectorizer(max_df=100)\n",
    "x_train = vectorizer.fit_transform(df_train['content'])\n",
    "y_train = df_train['score']\n",
    "x_test = vectorizer.transform(df_test['content'])\n",
    "y_test = df_test['score']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(stop_words=['\\ufeff$', '0', '1', '2', '3', '4', '5', '6', '7',\n",
      "                            '8', '9', '?', '_', '“', '”', '、', '。', '《', '》',\n",
      "                            '一', '一些', '一何', '一切', '一则', '一方面', '一旦', '一来',\n",
      "                            '一样', '一般', '一转眼', ...],\n",
      "                token_pattern='\\\\[?\\\\w+\\\\]?')\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型训练& 测试"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91       964\n",
      "           1       0.79      0.43      0.56       285\n",
      "\n",
      "    accuracy                           0.84      1249\n",
      "   macro avg       0.82      0.70      0.73      1249\n",
      "weighted avg       0.84      0.84      0.83      1249\n",
      "\n",
      "准确率: 0.8438751000800641\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pre = clf.predict(x_test)\n",
    "print(y_pre)\n",
    "\n",
    "# 测试\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pre))\n",
    "print('准确率:', metrics.accuracy_score(y_test, y_pre))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(clf, 'clf_model.m')\n",
    "print('ok!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 测试模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n"
     ]
    }
   ],
   "source": [
    "t_clf = joblib.load('clf_model.m')  # 导入模型\n",
    "print(t_clf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "t_df = pd.read_csv('../csv/test_label.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "t_df_pre = t_clf.predict(vectorizer.transform(t_df['content']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# t_df_pre =clf.predict(vectorizer.transform(t_df['content']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0] 307\n"
     ]
    }
   ],
   "source": [
    "print(t_df_pre,len(t_df_pre))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.96      0.61       140\n",
      "           1       0.00      0.00      0.00       167\n",
      "\n",
      "    accuracy                           0.44       307\n",
      "   macro avg       0.22      0.48      0.31       307\n",
      "weighted avg       0.20      0.44      0.28       307\n",
      "\n",
      "准确率: 0.43973941368078173\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(t_df['score'], t_df_pre))\n",
    "print('准确率:', metrics.accuracy_score(t_df['score'], t_df_pre))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}